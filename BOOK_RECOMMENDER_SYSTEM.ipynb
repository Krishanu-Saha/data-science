{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishanu-Saha/data-science/blob/main/BOOK_RECOMMENDER_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  BOOK_RECOMMENDER_SYSTEM\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individualby Krishanu Saha\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "\n",
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. The main objective is to create a book recommendation system for users."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import re\n",
        "import pickle\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SkRBcVX9IfLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "#User Dataset\n",
        "users_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/UNSUPERVISE ML/Users.csv')\n",
        "\n",
        "#Books Dataset\n",
        "books_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/UNSUPERVISE ML/Books.csv')\n",
        "\n",
        "#Ratings Dataset\n",
        "ratings_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/UNSUPERVISE ML/Ratings.csv')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "#User Dataset\n",
        "users_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books Dataset\n",
        "books_df.head()"
      ],
      "metadata": {
        "id": "7-ZW7xbkJkcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Dataset\n",
        "ratings_df.head()"
      ],
      "metadata": {
        "id": "4wrbex2SJz8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Users_df\n",
        "users_df.shape"
      ],
      "metadata": {
        "id": "sC01f6Z6KK2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of Users dataset is (278858, 3)"
      ],
      "metadata": {
        "id": "bCreG0MpKV-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Books Dataset\n",
        "books_df.shape"
      ],
      "metadata": {
        "id": "43QT94DSKegF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of Books dataset is (271360, 8)"
      ],
      "metadata": {
        "id": "wYOw5bcOKknW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Dataset\n",
        "ratings_df.shape"
      ],
      "metadata": {
        "id": "t30PanacKtVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of Ratings Dataset is (1149780, 3)"
      ],
      "metadata": {
        "id": "Hphotmp4K2Zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Dataset\n",
        "users_df.info()"
      ],
      "metadata": {
        "id": "3qMN7fsWLA_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books Dataset\n",
        "books_df.info()"
      ],
      "metadata": {
        "id": "GjMveI75LOkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Dataset\n",
        "ratings_df.info()"
      ],
      "metadata": {
        "id": "R_WC6po7LXoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Dataset\n",
        "len(users_df[users_df.duplicated()])"
      ],
      "metadata": {
        "id": "dvrUKmo2LhV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate Data counts in Users Df if 0"
      ],
      "metadata": {
        "id": "7lULwbuDMEXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Dataset\n",
        "len(books_df[books_df.duplicated()])"
      ],
      "metadata": {
        "id": "tSFRYcuAMAns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate Data counts in Books Df if 0"
      ],
      "metadata": {
        "id": "dUQIgEuRMVDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Dataset\n",
        "len(ratings_df[ratings_df.duplicated()])"
      ],
      "metadata": {
        "id": "Wm2WcHxeMDCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate Data counts in Ratings Df if 0"
      ],
      "metadata": {
        "id": "auDGcWTRMYIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install missingno"
      ],
      "metadata": {
        "id": "xLx4BvIKM_Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno"
      ],
      "metadata": {
        "id": "FvxQHPDbNBy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Dataset\n",
        "users_df.isnull().sum()"
      ],
      "metadata": {
        "id": "1fa6nDiSNL2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(users_df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books Dataset\n",
        "books_df.isnull().sum()"
      ],
      "metadata": {
        "id": "Skr9QrEJNzxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(books_df)"
      ],
      "metadata": {
        "id": "PDEaGUTONoDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Dataset\n",
        "ratings_df.isnull().sum()"
      ],
      "metadata": {
        "id": "sNP5lRgYOI-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of Users dataset is (278858, 3)The shape of Books dataset is (271360, 8)The shape of Ratings Dataset is (1149780, 3)Duplicate Data counts in Users Df if 0 Duplicate Data counts in Books Df if 0 Duplicate Data counts in Ratings Df if 0\n",
        "\n",
        "User-ID          0\n",
        "Location         0\n",
        "Age         110762\n",
        "dtype: int64\n",
        "\n",
        "ISBN                   0\n",
        "Book-Title             0\n",
        "Book-Author            1\n",
        "Year-Of-Publication    0\n",
        "Publisher              2\n",
        "Image-URL-S            0\n",
        "Image-URL-M            0\n",
        "Image-URL-L            3\n",
        "dtype: int64\n",
        "\n",
        "User-ID        0\n",
        "ISBN           0\n",
        "Book-Rating    0\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "w8ENzWjWWmwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(ratings_df)"
      ],
      "metadata": {
        "id": "0BFT0_xDNoXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Users dataset contains 278,858 rows and 3 columns, the Books dataset contains 271,360 rows and 8 columns, and the Ratings dataset contains 1,149,780 rows and 3 columns. The duplicate data counts in all three datasets are zero, indicating that there are no duplicate values present in the datasets. However, the Users dataset has 110,762 missing values in the Age column. The Books dataset has missing values in Book-Author, Publisher, and Image-URL-L columns, while the Ratings dataset has no missing values. The datasets are ready for further analysis, and the missing values in the Age, Book-Author, Publisher, and Image-URL-L columns need to be addressed to make the datasets more informative."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.columns"
      ],
      "metadata": {
        "id": "sZdUieK2POMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.columns"
      ],
      "metadata": {
        "id": "syF6NVOWPSUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.columns"
      ],
      "metadata": {
        "id": "DDNW_pLoPXIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.describe()"
      ],
      "metadata": {
        "id": "wnusrr6sPfrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.describe()"
      ],
      "metadata": {
        "id": "R1r2O1eoPojP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.describe()"
      ],
      "metadata": {
        "id": "M--D0APVQEAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.nunique()"
      ],
      "metadata": {
        "id": "hQP0mFZwQne_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.nunique()"
      ],
      "metadata": {
        "id": "aTNGqeVUQtAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.nunique()"
      ],
      "metadata": {
        "id": "5M-poNVnQyNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Cleaning and Pre-Processing***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BOOKS DATASET**"
      ],
      "metadata": {
        "id": "ZlfYNuQskAby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the unwanted columns Image-URL-S, Image-URL-M, and Image-URL-L\n",
        "books_df.drop([\"Image-URL-S\", \"Image-URL-M\", \"Image-URL-L\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "fsZhycrpYOBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pointing out observation where Book_Author is null\n",
        "books_df.loc[books_df['Book-Author'].isnull(),:]"
      ],
      "metadata": {
        "id": "KnMcuerSZfjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mode (most common value) of the 'Book-Author' column\n",
        "mode_author = books_df['Book-Author'].mode()[0]\n",
        "\n",
        "# Fill the missing values in the 'Book-Author' column with the mode value\n",
        "books_df['Book-Author'].fillna(mode_author, inplace=True)"
      ],
      "metadata": {
        "id": "tya9kn-zajC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is used to filter the rows of the books_df DataFrame where the Publisher column has a missing value\n",
        "books_df.loc[books_df['Publisher'].isnull(),:]"
      ],
      "metadata": {
        "id": "1KEwnx4mZ9Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking for null values\n",
        "books_df.isnull().sum() "
      ],
      "metadata": {
        "id": "V73T11LpZawI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mode (most common value) of the 'Publisher' column\n",
        "mode_publisher = books_df['Publisher'].mode()[0]\n",
        "\n",
        "# Fill the missing values in the 'Publisher' column with the mode value\n",
        "books_df['Publisher'].fillna(mode_publisher,inplace = True)"
      ],
      "metadata": {
        "id": "s04JzLZ_a-y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking for column Year-of-publication\n",
        "books_df['Year-Of-Publication'].unique()"
      ],
      "metadata": {
        "id": "ovJl_lhVcP5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking where Year-Of-Publication has DK Publishing Inc value\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'DK Publishing Inc',:]"
      ],
      "metadata": {
        "id": "lTW8MkCRcgJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the value at row 209538 in the 'Publisher' column to 'DK Publishing Inc'\n",
        "books_df.at[209538 ,'Publisher'] = 'DK Publishing Inc'\n",
        "\n",
        "# Update the value at row 209538 in the 'Year-Of-Publication' column to 2000\n",
        "books_df.at[209538 ,'Year-Of-Publication'] = 2000\n",
        "\n",
        "# Update the value at row 209538 in the 'Book-Title' column to 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
        "\n",
        "# Update the value at row 209538 in the 'Book-Author' column to 'Michael Teitelbaum'\n",
        "books_df.at[209538 ,'Book-Author'] = 'Michael Teitelbaum'\n"
      ],
      "metadata": {
        "id": "M4iRYImccnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the value at row 221678 in the 'Publisher' column to 'DK Publishing Inc'\n",
        "books_df.at[221678 ,'Publisher'] = 'DK Publishing Inc'\n",
        "\n",
        "# Update the value at row 221678 in the 'Year-Of-Publication' column to 2000\n",
        "books_df.at[221678 ,'Year-Of-Publication'] = 2000\n",
        "\n",
        "# Update the value at row 209538 in the 'Book-Title' column to 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
        "\n",
        "# Update the value at row 209538 in the 'Book-Author' column to 'James Buckley'\n",
        "books_df.at[209538 ,'Book-Author'] = 'James Buckley'\n"
      ],
      "metadata": {
        "id": "pNtSrd-_dLRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use boolean indexing to select all rows where the 'Year-Of-Publication' column has the value 'Gallimard'\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'Gallimard',:]\n"
      ],
      "metadata": {
        "id": "NMs31--mdVVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the values in specific cells of the DataFrame using .at[] and index location\n",
        "books_df.at[220731 ,'Publisher'] = 'Gallimard'\n",
        "books_df.at[220731 ,'Year-Of-Publication'] = '2003'\n",
        "books_df.at[209538 ,'Book-Title'] = 'Peuple du ciel - Suivi de Les bergers '\n",
        "books_df.at[209538 ,'Book-Author'] = 'Jean-Marie Gustave Le ClÃ?Â©zio'"
      ],
      "metadata": {
        "id": "eRtIRUG-dfuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting year of publication to int type from object\n",
        "books_df['Year-Of-Publication'] = books_df['Year-Of-Publication'].astype(int)"
      ],
      "metadata": {
        "id": "yar8ht_JdmXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the values in 'Year-Of-Publication' column to NaN where the value is less than 1900 or greater than 2023\n",
        "books_df.loc[(books_df['Year-Of-Publication'] < 1900) | (books_df['Year-Of-Publication'] > 2023), 'Year-Of-Publication'] = np.nan\n"
      ],
      "metadata": {
        "id": "M7D_8JdifET4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_year = books_df['Year-Of-Publication'].mode()[0]  # Get the mode year\n",
        "books_df['Year-Of-Publication'].fillna(mode_year, inplace=True)  # Impute missing values with the mode"
      ],
      "metadata": {
        "id": "RHlaA73pfU4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.info()"
      ],
      "metadata": {
        "id": "DkOUy9xafej7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USERS DATASET**"
      ],
      "metadata": {
        "id": "T_bbv-RAbtLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the Age column\n",
        "print(users_df[\"Age\"].isnull().sum())\n"
      ],
      "metadata": {
        "id": "M64GiJW2Y7MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Age column has 11072 null values."
      ],
      "metadata": {
        "id": "CzxE-mDcj1GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in the Age column with the median value\n",
        "median_age = users_df[\"Age\"].median()\n",
        "users_df[\"Age\"].fillna(median_age, inplace=True)\n"
      ],
      "metadata": {
        "id": "PMUH9FDmju9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again for missing values in the Age column\n",
        "print(users_df[\"Age\"].isnull().sum())"
      ],
      "metadata": {
        "id": "lf3PEsm0jyIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_lower, age_upper = np.percentile(users_df['Age'], [1, 99])  # Get the 1st and 99th percentiles of Age\n",
        "users_df['Age'] = users_df['Age'].clip(lower=age_lower, upper=age_upper)  # Winsorize the Age column"
      ],
      "metadata": {
        "id": "jo1DJemzgpwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.head()"
      ],
      "metadata": {
        "id": "cC2CcZYYhJiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values with empty string\n",
        "users_df['Location'] = users_df['Location'].fillna('')\n",
        "\n",
        "# Split 'Location' column into separate columns\n",
        "users_df[['City', 'State', 'Country']] = users_df['Location'].str.split(', ', n=2, expand=True)"
      ],
      "metadata": {
        "id": "CfDOkqCDh3z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.drop('Location', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "6FU2e1O7i__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = users_df.duplicated()\n",
        "print('Number of duplicate rows = %d' % duplicate_rows.sum())"
      ],
      "metadata": {
        "id": "cezOiim9jIh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.head()"
      ],
      "metadata": {
        "id": "HExNauSZik70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RATINGS DATASET**"
      ],
      "metadata": {
        "id": "ymMuNWpQnelI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.info()"
      ],
      "metadata": {
        "id": "XbkusOcnotWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n"
      ],
      "metadata": {
        "id": "NiDbYDfcnpCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract ISBNs from books dataset\n",
        "book_ISBN = books_df['ISBN'].str.extract('(\\d{10}|\\d{13})', expand=False)\n",
        "\n",
        "# identify ratings with ISBNs not matching the pattern in books dataset\n",
        "non_matching_ISBN = ~ratings_df['ISBN'].str.match('^(\\d{10}|\\d{13})$')\n",
        "\n",
        "# get the unique non-matching ISBNs\n",
        "unique_non_matching_ISBN = ratings_df.loc[non_matching_ISBN, 'ISBN'].unique()\n",
        "\n",
        "# create a mapping of non-matching ISBNs to their corrected versions\n",
        "corrections = dict(zip(unique_non_matching_ISBN, book_ISBN[book_ISBN.isin(unique_non_matching_ISBN)]))\n",
        "\n",
        "# apply the corrections to the ratings dataset\n",
        "ratings_df['ISBN'].replace(corrections, inplace=True)\n",
        "## Uppercasing all alphabets in ISBN\n",
        "ratings_df['ISBN'] = ratings_df['ISBN'].str.upper()\n"
      ],
      "metadata": {
        "id": "iW-T35hSqqPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uppercasing all alphabets in ISBN\n",
        "ratings_df['ISBN'] = ratings_df['ISBN'].str.upper()"
      ],
      "metadata": {
        "id": "cbOJi_KCrBX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.head()"
      ],
      "metadata": {
        "id": "e0KaxIb9rRIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MERGING THE DATASETS : BOOKS_DF,USERS_DF AND RATINGS_DF**"
      ],
      "metadata": {
        "id": "EynvZPVsrm5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the 'books_df' and 'ratings_df' DataFrames on 'ISBN' column\n",
        "df = pd.merge(books_df, ratings_df, on='ISBN', how='inner')\n",
        "\n",
        "# Merge the resulting DataFrame with 'users_df' DataFrame on 'User-ID' column\n",
        "df = pd.merge(df, users_df, on='User-ID', how='inner')\n"
      ],
      "metadata": {
        "id": "r5XNmtoZr1V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the manipulations and insights found:\n",
        "\n",
        "Drop unwanted columns: The columns \"Image-URL-S\", \"Image-URL-M\", and \"Image-URL-L\" have been dropped from the books_df dataset.\n",
        "\n",
        "Fill missing values: The missing values in the \"Book-Author\" and \"Publisher\" columns in the books_df dataset have been filled with the mode value.\n",
        "\n",
        "Fix data errors: There were some errors in the \"Year-Of-Publication\" column of the books_df dataset. Some values were not integers, and some values were outside the valid range of years. These errors were fixed by converting the column to an integer type and imputing missing values with the mode. The values outside the valid range were also imputed with missing values.\n",
        "\n",
        "Handle missing values: The missing values in the \"Age\" column of the users_df dataset were filled with the median value. The \"Location\" column was also replaced with an empty string.\n",
        "\n",
        "Split column: The \"Location\" column in the users_df dataset was split into three columns: \"City\", \"State\", and \"Country\".\n",
        "\n",
        "Remove duplicates: Duplicate rows were removed from the users_df dataset.\n",
        "\n",
        "Data correction: The ISBN values in the ratings_df dataset were checked for validity against the ISBN values in the books_df dataset. Non-matching ISBNs were corrected using a mapping of non-matching ISBNs to their corrected versions.\n",
        "\n",
        "Merge datasets: The cleaned and corrected books_df, ratings_df, and users_df datasets were merged into a single dataframe \"df\" using inner joins.\n",
        "\n",
        "Overall, these manipulations aim to clean and preprocess the data, handle missing values and outliers, and correct errors and inconsistencies in the data to prepare it for further analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of book ratings in the dataset**"
      ],
      "metadata": {
        "id": "POfPJvFV7E4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average rating for books in the dataset\n",
        "avg_rating = df['Book-Rating'].mean()\n",
        "\n",
        "# Plot the distribution of book ratings\n",
        "plt.hist(df['Book-Rating'], bins=10)\n",
        "plt.title('Distribution of Book Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Number of Books')\n",
        "plt.show()\n",
        "\n",
        "# Print the average rating for books in the dataset\n",
        "print('Average rating: ', avg_rating)"
      ],
      "metadata": {
        "id": "t5K6Clr63VRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "NCpk-ym6CnoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the code, a histogram graph has been chosen to represent the distribution of book ratings. A histogram is a type of bar graph that shows the distribution of a set of continuous data. In this case, the data is the book ratings, which is continuous and can take on a range of values. The histogram represents the frequency of ratings falling into different bins, where each bin represents a range of values.\n",
        "\n",
        "The histogram is a good choice for this type of data because it allows us to see the distribution of the ratings and how they are distributed across different bins. It helps us to visualize the range of ratings that are common, and also shows any outliers or extreme values. In addition, it allows us to see the shape of the distribution, which can be useful for making inferences about the underlying population."
      ],
      "metadata": {
        "id": "Z7QqNhRwAXtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS** "
      ],
      "metadata": {
        "id": "8StJYuRfKem7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe from the graph that a huge portion of number of books has not been rated.\n",
        "\n",
        "The count of books which has been rated 10 is highest."
      ],
      "metadata": {
        "id": "eXENUQxYKmKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "FHie3zaW7zHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that a large portion of books has not been rated may indicate that there is an opportunity for businesses in the book industry to encourage users to rate books. This could be done through incentivizing ratings or creating a more user-friendly rating system. On the other hand, the insight that books with a rating of 10 are the most frequent may indicate that users have a strong preference for highly-rated books. Businesses in the book industry could use this information to focus on promoting and marketing highly-rated books to attract more readers and increase sales."
      ],
      "metadata": {
        "id": "piYhF83q0T7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The most popular books in the dataset based on the number of ratings**"
      ],
      "metadata": {
        "id": "8OB4w_217TUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the number of ratings for each book\n",
        "book_ratings_count = pd.DataFrame(df.groupby(['ISBN', 'Book-Title'])['Book-Rating'].count())\n",
        "\n",
        "# Sort the books by the number of ratings in descending order\n",
        "book_ratings_count.sort_values('Book-Rating', ascending=False, inplace=True)\n",
        "\n",
        "# Print the top 10 most popular books\n",
        "print(book_ratings_count.head(10))\n"
      ],
      "metadata": {
        "id": "fkKec7br4K8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart of the top 10 most popular books\n",
        "plt.bar(book_ratings_count.head(10).index.get_level_values('Book-Title'), book_ratings_count.head(10)['Book-Rating'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.title('Top 10 Most Popular Books')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lpYdycREAtOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "yzgESxN-Clxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart of the top 10 most popular books, based on the number of ratings each book has received. A bar chart is a good choice for this type of data because it shows the magnitude of each book's popularity relative to the others, and it makes it easy to compare the number of ratings for each book.\n",
        "\n",
        "In this case, the x-axis represents the titles of the books, while the y-axis represents the number of ratings. The bars are used to visually represent the number of ratings for each book, with the height of each bar indicating the number of ratings received by the corresponding book.\n",
        "\n",
        "The code also rotates the x-axis labels by 90 degrees to prevent overlapping of the labels when they are long or numerous.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the top 10 most popular books based on the number of ratings, as it provides a clear and easy-to-understand representation of the data."
      ],
      "metadata": {
        "id": "2yRTzUPYAgpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS** "
      ],
      "metadata": {
        "id": "Y9nSDs5n5r6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 most popular books:\n",
        "\n",
        "Wild Animus                                               \n",
        "The Lovely Bones: A Novel                                  \n",
        "The Da Vinci Code                                          \n",
        "Divine Secrets of the Ya-Ya Sisterhood: A Novel             \n",
        "The Red Tent (Bestselling Backlist)                         \n",
        "A Painted House                                             \n",
        "Snow Falling on Cedars                                      \n",
        "The Secret Life of Bees                                     \n",
        "Angels &amp; Demons                                         \n",
        "Where the Heart Is (Oprah's Book Club (Paperback))"
      ],
      "metadata": {
        "id": "X5yVAlTML4ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "-hpocGzY7xmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " if a book retailer's goal is to stock and sell popular books, then knowing the top 10 most popular books can be beneficial to the business.\n",
        "\n",
        "Regarding negative growth, it's not clear from the statement if any insights have led to negative growth. The fact that a huge portion of the books in the dataset has not been rated may limit the usefulness of the data in making business decisions, but it's not necessarily a negative impact."
      ],
      "metadata": {
        "id": "R-yKcCsj0iyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10 most popular publishers**"
      ],
      "metadata": {
        "id": "idf0ZR497lhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the number of ratings for each publisher\n",
        "publisher_ratings_count = pd.DataFrame(df.groupby('Publisher')['Book-Rating'].count())\n",
        "\n",
        "# Sort the publishers by the number of ratings in descending order\n",
        "publisher_ratings_count.sort_values('Book-Rating', ascending=False, inplace=True)\n",
        "\n",
        "# Print the top 10 most popular publishers\n",
        "print(publisher_ratings_count.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "bFxyV2Rj6KvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart of the top 10 most popular publishers\n",
        "plt.bar(publisher_ratings_count.head(10).index, publisher_ratings_count.head(10)['Book-Rating'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.title('Top 10 Most Popular Publishers based on count of Book-Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZMHUyj4LAycT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "MZyYaoM6CkM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart of the top 10 most popular publishers, based on the number of ratings received by their books. A bar chart is a good choice for this type of data because it allows for easy comparison between the different publishers and the number of ratings their books have received.\n",
        "\n",
        "In this case, the x-axis represents the names of the publishers, while the y-axis represents the number of ratings. The bars are used to visually represent the number of ratings for each publisher, with the height of each bar indicating the number of ratings received by the corresponding publisher.\n",
        "\n",
        "The code also rotates the x-axis labels by 90 degrees to prevent overlapping of the labels when they are long or numerous.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the top 10 most popular publishers based on the number of ratings, as it provides a clear and easy-to-understand representation of the data. It helps to identify which publishers are more popular among the readers based on their books' ratings.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQB9HsNdArZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS** "
      ],
      "metadata": {
        "id": "f9IooonJ51yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10 publisher based on counts**\n",
        "\n",
        "Ballantine Books                \n",
        "Pocket                          \n",
        "Berkley Publishing Group        \n",
        "Warner Books                    \n",
        "Harlequin                       \n",
        "Bantam Books                    \n",
        "Bantam                         \n",
        "Signet Book                     \n",
        "Avon                            \n",
        "Penguin Books "
      ],
      "metadata": {
        "id": "ceuz6pkeve95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "iAI5Nizb7woa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the top 10 publishers in the dataset, a business impact could be to focus on building relationships with these publishers in order to potentially gain exclusive access to their upcoming releases, negotiate better pricing or discounts, and establish a strong reputation within the industry by promoting and distributing their books to a wider audience. It could also help to identify which genres these publishers specialize in and use this information to tailor marketing strategies to specific target audiences. Additionally, these publishers could potentially be used as a benchmark for measuring success and setting performance goals."
      ],
      "metadata": {
        "id": "oJ3uBkcl6AkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10 Most Popular Authors**"
      ],
      "metadata": {
        "id": "tDzEgAho7ufS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the number of ratings for each author\n",
        "author_ratings_count = pd.DataFrame(df.groupby('Book-Author')['Book-Rating'].count())\n",
        "\n",
        "# Sort the authors by the number of ratings in descending order\n",
        "author_ratings_count.sort_values('Book-Rating', ascending=False, inplace=True)\n",
        "\n",
        "# Print the top 10 most popular authors\n",
        "print(author_ratings_count.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "QllCQQBW6Mf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart of the top 10 most popular authors\n",
        "plt.bar(author_ratings_count.head(10).index, author_ratings_count.head(10)['Book-Rating'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.title('Top 10 Authors based on counts of Book-Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aA7da6KbA1DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "k2Y5hc-ACieV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart of the top 10 most popular authors, based on the number of ratings received by their books. A bar chart is a good choice for this type of data because it allows for easy comparison between the different authors and the number of ratings their books have received.\n",
        "\n",
        "In this case, the x-axis represents the names of the authors, while the y-axis represents the number of ratings. The bars are used to visually represent the number of ratings for each author, with the height of each bar indicating the number of ratings received by the corresponding author.\n",
        "\n",
        "The code also rotates the x-axis labels by 90 degrees to prevent overlapping of the labels when they are long or numerous.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the top 10 most popular authors based on the number of ratings, as it provides a clear and easy-to-understand representation of the data. It helps to identify which authors are more popular among the readers based on their books' ratings."
      ],
      "metadata": {
        "id": "i-_8N0m_A42T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "zN7hFYGx6XUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stephen King , Nora Roberts and john Grisham are the top 3 authors based on count of book-rating."
      ],
      "metadata": {
        "id": "z0koYB-J24JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "H7_vcC8q7vlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis can potentially lead to a positive business impact for the book industry. For example, identifying the most popular books, authors, and publishers can help businesses make strategic decisions such as which books to stock, which authors to feature, and which publishers to partner with.\n",
        "\n",
        "However, there are also some insights that can lead to negative growth. For example, if the analysis reveals that a significant portion of the books in the dataset have not been rated, this could indicate a lack of interest in those books or a lack of engagement with the platform. Additionally, if the analysis shows that users from certain regions tend to rate books lower on average, this could indicate a potential issue with targeting those regions for book sales and marketing efforts. It is important to consider these potential negative impacts and take them into account when making business decisions based on the insights gained from the analysis."
      ],
      "metadata": {
        "id": "1dvh6FJr3Ynz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis how the number of books published each year has changed over time**"
      ],
      "metadata": {
        "id": "iazz_skZ6339"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the number of books published each year\n",
        "books_published_per_year = pd.DataFrame(df.groupby('Year-Of-Publication')['ISBN'].count())\n",
        "\n",
        "# Sort the years by the number of books published in ascending order\n",
        "books_published_per_year.sort_values('Year-Of-Publication', ascending=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "q525AMPL6xmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a line chart of the number of books published each year\n",
        "plt.plot(books_published_per_year.index, books_published_per_year['ISBN'])\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Books Published')\n",
        "plt.title('Number of Books Published Each Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6OjjbMT7A3D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "hxwaaL8aCbny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a line chart of the number of books published each year. A line chart is a good choice for this type of data because it allows for easy visualization of the trend in the number of books published over time.\n",
        "\n",
        "In this case, the x-axis represents the years in which the books were published, while the y-axis represents the number of books published. The line is used to visually represent the trend in the number of books published each year, with the slope of the line indicating the rate of change.\n",
        "\n",
        "The code also includes axis labels and a title to make the graph easy to understand.\n",
        "\n",
        "Overall, a line chart is a good choice for displaying the trend in the number of books published each year, as it provides a clear and easy-to-understand representation of the data. It helps to identify any patterns or changes in the number of books published over time."
      ],
      "metadata": {
        "id": "FlaJpIXOBAj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "most_popular_year = books_published_per_year['ISBN'].idxmax()\n",
        "print(f\"The most popular year for book publishing in the dataset was {most_popular_year}.\")"
      ],
      "metadata": {
        "id": "e9OVYjqp8WE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "xWxrSkOO6eOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most popular year for book publishing in the dataset was 2002"
      ],
      "metadata": {
        "id": "is7M8GtGwNi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "z_PD63Lp7ugj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on this insight alone, it is difficult to determine if it will have a positive business impact or not. However, if a business is involved in the book publishing industry, they may use this information to make strategic decisions about the timing of their book releases or marketing efforts. For example, they may choose to release more books in 2002 or around that time to capitalize on the high popularity of book publishing during that year."
      ],
      "metadata": {
        "id": "V18MkaXU3nUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of ratings given by users**"
      ],
      "metadata": {
        "id": "AQ3oh-Hn9QgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the distribution of ratings given by users\n",
        "ratings_distribution = pd.DataFrame(df.groupby('User-ID')['Book-Rating'].mean())\n"
      ],
      "metadata": {
        "id": "XmKoa0Hl9VLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram of the distribution of ratings given by users\n",
        "plt.hist(ratings_distribution['Book-Rating'], bins=10)\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Ratings Given by Users')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtBbwkJ5A5dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "as9WGWPyCOJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen graph is a histogram, which is a type of bar graph that shows the distribution of a continuous variable (in this case, the ratings given by users). It is an appropriate choice because it allows us to see how the ratings are distributed, i.e., the frequency of each rating. The histogram is divided into bins, with each bin representing a range of values for the variable being measured (in this case, ratings). The height of each bar represents the number of observations (users) that fall into that bin. The x-axis represents the values of the variable being measured, and the y-axis represents the frequency of observations. The histogram is a useful tool for visualizing the shape of a distribution and identifying patterns, such as skewness, central tendency, and outliers."
      ],
      "metadata": {
        "id": "6xkFf9buCXvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "Nohzc6DA6iGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large of portion of users have not rated any book.\n",
        "\n",
        "The books which are rated 10 and 9 are the most frequent one."
      ],
      "metadata": {
        "id": "Im0XHTjAwWxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "2u9F91kh7tlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that a large portion of users have not rated any book may lead to a negative impact on the business, as it suggests that there is a lack of user engagement with the platform or the books being offered. This may result in lower sales and revenue for the company.\n",
        "\n",
        "On the other hand, the insight that the books rated 10 and 9 are the most frequent ones can have a positive impact on the business, as it suggests that users are highly satisfied with the books they have read and are likely to recommend them to others. This may lead to higher sales and revenue as well as a positive reputation for the company."
      ],
      "metadata": {
        "id": "A4dDUA2R3zkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of users demographics**"
      ],
      "metadata": {
        "id": "CKbjDVKy39az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_info = df.groupby('User-ID').agg({'Age': 'mean', 'City': 'first', 'State': 'first', 'Country': 'first'})\n",
        "print(user_info.head())"
      ],
      "metadata": {
        "id": "40RVwZEu-L6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "bKnjTiKx6nOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting DataFrame shows the mean age, city, state, and country of each user in the dataset. We can use this information to gain insights into the demographics of the users, such as the age range of the users, the most common locations of the users, and the countries represented in the dataset.\n",
        "\n",
        "For example, we can see that the mean age of users is around 34 years old. We can also see that the most common location of users is in the United States (based on the State column) and that there are users from other countries as well, such as Canada and Spain (based on the Country column). These insights can be used to tailor marketing strategies or book recommendations to different user groups based on their demographics."
      ],
      "metadata": {
        "id": "7LFavyB54b3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Study of the popularity of books by different authors**"
      ],
      "metadata": {
        "id": "mOu3s65v_npq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the number of books written by each author\n",
        "author_counts = df['Book-Author'].value_counts().reset_index()\n",
        "author_counts.columns = ['Book-Author', 'Book-Count']\n",
        "\n",
        "# Create a DataFrame with the average rating for books written by each author\n",
        "author_ratings = df.groupby('Book-Author')['Book-Rating'].mean().reset_index()\n",
        "author_ratings.columns = ['Book-Author', 'Average-Rating']\n",
        "\n",
        "# Merge the two DataFrames on the Book-Author column\n",
        "author_data = pd.merge(author_counts, author_ratings, on='Book-Author')\n",
        "\n",
        "# Print the top 10 authors by book count and average rating\n",
        "print(author_data.sort_values(['Book-Count', 'Average-Rating'], ascending=False).head(10))"
      ],
      "metadata": {
        "id": "XHhhfeFl-0WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stephen King , Nora Roberts and john Grihsham are the top 3 authors based on the book counts."
      ],
      "metadata": {
        "id": "FBdn4d_rxMlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of the books by publisher or author**"
      ],
      "metadata": {
        "id": "HRU-PG0Y_wZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the count of books published by each publisher\n",
        "publisher_counts = df['Publisher'].value_counts().reset_index()\n",
        "publisher_counts.columns = ['Publisher', 'Book-Count']\n",
        "\n",
        "# Create a DataFrame with the average rating for books published by each publisher\n",
        "publisher_ratings = df.groupby('Publisher')['Book-Rating'].mean().reset_index()\n",
        "publisher_ratings.columns = ['Publisher', 'Average-Rating']\n",
        "\n",
        "# Merge the two DataFrames on the Publisher column\n",
        "publisher_data = pd.merge(publisher_counts, publisher_ratings, on='Publisher')\n",
        "\n",
        "# Print the top 10 publishers by book count and average rating\n",
        "print(publisher_data.sort_values(['Book-Count', 'Average-Rating'], ascending=False).head(10))"
      ],
      "metadata": {
        "id": "OtY87Q82-4Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ballantine, Books Pocket Berkley and Publishing Group are the top 3 publishers based on book counts."
      ],
      "metadata": {
        "id": "2wcqnhyux2Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation between publication year and rating\n",
        "corr = df['Year-Of-Publication'].corr(df['Book-Rating'])\n",
        "\n",
        "print(f\"Correlation between publication year and rating: {corr:.2f}\")"
      ],
      "metadata": {
        "id": "rJi88kd2BRMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation between publication year and rating: 0.04"
      ],
      "metadata": {
        "id": "pHGWpiljxsZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "YP_2kAtp8PK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation coefficient of 0.04 suggests a very weak positive correlation between publication year and rating. This means that there is no significant relationship between the year a book was published and its rating.\n",
        "\n",
        "From a business perspective, this insight may not have a significant impact as it suggests that there is no particular advantage or disadvantage to publishing books in a particular year. However, it is important to note that there may be other factors that influence a book's rating such as the author, genre, and publisher. Therefore, it is important to consider multiple factors when making business decisions related to book publishing."
      ],
      "metadata": {
        "id": "BfysUxpW8FPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation between publisher and rating\n",
        "corr = df.groupby('Publisher')['Book-Rating'].mean().corr(df.groupby('Publisher')['Book-Rating'].count())\n",
        "\n",
        "print(f\"Correlation between publisher and rating: {corr:.2f}\")"
      ],
      "metadata": {
        "id": "gNo4zxNlBULn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation between publisher and rating: -0.02"
      ],
      "metadata": {
        "id": "MC1RHqQtxu8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "vKCySTUp8UTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation coefficient of -0.02 indicates a very weak negative correlation between the publisher and rating. This suggests that there is no significant relationship between the publisher and the rating of a book. Therefore, this insight may not have a strong business impact on its own, but it can be used in conjunction with other insights to gain a more comprehensive understanding of the factors that affect book ratings."
      ],
      "metadata": {
        "id": "1OFxjODD8M9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of users across different countries**."
      ],
      "metadata": {
        "id": "EDjK6VWPD_FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of users in each country\n",
        "country_counts = df['Country'].value_counts().head(15)\n",
        "\n",
        "# Plot the results using a bar chart\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(country_counts.index, country_counts.values)\n",
        "\n",
        "# Set chart title and labels\n",
        "ax.set_title('Distribution of Users by Country (Top 15)')\n",
        "ax.set_xlabel('Country')\n",
        "ax.set_ylabel('Number of Users')\n",
        "\n",
        "# Rotate the x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vw7K0NUNEE2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "O0N4nBoxCHjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart to show the distribution of users by country. A bar chart is a good choice for this type of data because it allows for easy comparison between the different countries and the number of users in each country.\n",
        "\n",
        "In this case, the x-axis represents the different countries, while the y-axis represents the number of users in each country. The bars are used to visually represent the number of users in each country, with the height of each bar indicating the number of users in the corresponding country.\n",
        "\n",
        "The code also includes axis labels and a title to make the graph easy to understand. Additionally, the x-axis labels are rotated by 90 degrees for better readability.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the distribution of users by country, as it provides a clear and easy-to-understand representation of the data. It helps to identify which countries have the most users in the dataset and to compare the number of users across different countries."
      ],
      "metadata": {
        "id": "ga_cx-1RBM-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "SOjROWKs6yDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of users are maximum in country usa. "
      ],
      "metadata": {
        "id": "ia7Io6QdyGXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "uiYRysi27nLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the number of users is maximum in the country USA, it suggests that the business may want to focus more on this market to increase its reach and revenue. This could involve targeted marketing and advertising campaigns to attract more users from this region, as well as offering promotions or discounts to incentivize users to purchase more books. Additionally, the business could consider partnering with local publishers or booksellers in the USA to expand its offerings and improve its competitiveness in the market. Overall, having a large user base in a particular region presents an opportunity for the business to grow and increase its profitability."
      ],
      "metadata": {
        "id": "cd_5198j43Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe to only include users from the USA\n",
        "usa_df = df[df['Country'] == 'usa']\n",
        "\n",
        "# Count the number of users in each state\n",
        "state_counts = usa_df['State'].value_counts().head(15)\n",
        "\n",
        "# Plot the results using a bar chart or histogram\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(state_counts.index, state_counts.values)\n",
        "\n",
        "# Set chart title and labels\n",
        "ax.set_title('Distribution of Users by State (USA)')\n",
        "ax.set_xlabel('State')\n",
        "ax.set_ylabel('Number of Users')\n",
        "\n",
        "# Rotate the x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E6vXCexrIhl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "2z_3yydMCF__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart to show the distribution of users by state in the USA. A bar chart is a good choice for this type of data because it allows for easy comparison between the different states and the number of users in each state.\n",
        "\n",
        "In this case, the x-axis represents the different states in the USA, while the y-axis represents the number of users in each state. The bars are used to visually represent the number of users in each state, with the height of each bar indicating the number of users in the corresponding state.\n",
        "\n",
        "The code also includes axis labels and a title to make the graph easy to understand. Additionally, the x-axis labels are rotated by 90 degrees for better readability.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the distribution of users by state in the USA, as it provides a clear and easy-to-understand representation of the data. It helps to identify which states have the most users in the dataset and to compare the number of users across different states."
      ],
      "metadata": {
        "id": "zGxAT0YPBXws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "8FgM4e7F61qZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in country usa ,california state has the highest number of users followed by texas."
      ],
      "metadata": {
        "id": "kWYZkYXZyZYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "RijW2Dqu7mS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that California has the highest number of users in the USA could be useful for businesses that want to target their marketing efforts towards a specific geographic location. For example, a book retailer may choose to focus its advertising campaigns in California to increase its customer base in the state. Similarly, businesses can tailor their inventory and promotions to the reading preferences of users in California based on the genre of books that are popular in the region. By understanding the demographics and reading habits of users in different regions, businesses can make more informed decisions about their marketing strategies, product offerings, and inventory management."
      ],
      "metadata": {
        "id": "jzUI9dnE4-8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the distribution of users across different states or cities**"
      ],
      "metadata": {
        "id": "o3IBX3ilExIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of users in each city\n",
        "city_counts = df['City'].value_counts().head(15)\n",
        "\n",
        "# Plot the results using a bar chart or histogram\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(city_counts.index, city_counts.values)\n",
        "\n",
        "# Set chart title and labels\n",
        "ax.set_title('Distribution of Users by City(TOP 15)')\n",
        "ax.set_xlabel('City')\n",
        "ax.set_ylabel('Number of Users')\n",
        "\n",
        "# Rotate the x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8yrTnLwzE84h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "MuRtH0RuB53Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a bar chart to show the distribution of users by city. A bar chart is a good choice for this type of data because it allows for easy comparison between the different cities and the number of users in each city.\n",
        "\n",
        "In this case, the x-axis represents the different cities, while the y-axis represents the number of users in each city. The bars are used to visually represent the number of users in each city, with the height of each bar indicating the number of users in the corresponding city.\n",
        "\n",
        "The code also includes axis labels and a title to make the graph easy to understand. Additionally, the x-axis labels are rotated by 90 degrees for better readability.\n",
        "\n",
        "Overall, a bar chart is a good choice for displaying the distribution of users by city, as it provides a clear and easy-to-understand representation of the data. It helps to identify which cities have the most users in the dataset and to compare the number of users across different cities."
      ],
      "metadata": {
        "id": "yONjBWKHCCJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "NZFKngvh65DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in terms of city toronto has the highest number of users followed by chicago."
      ],
      "metadata": {
        "id": "EbstoAdCywV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "WvTwhMOZ7lZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The business impact of having a high number of users in certain locations such as California, Texas, Toronto and Chicago could be significant. Companies can use this information to target their marketing efforts more effectively and tailor their offerings to the specific preferences of users in these locations. For example, they can create regional promotions or partnerships with local businesses to increase brand awareness and drive sales. They can also analyze the reading habits and preferences of users in these locations to inform their product development and inventory management strategies. By understanding where their users are located and what they want, companies can optimize their operations and create a better customer experience, ultimately leading to increased revenue and growth."
      ],
      "metadata": {
        "id": "0WNd3akm5RGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of whether there is a correlation between the location of a user and the rating they give to a book.**"
      ],
      "metadata": {
        "id": "q28zeC05GTmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram of user ages\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.hist(df['Age'], bins=20)\n",
        "\n",
        "# Set chart title and labels\n",
        "ax.set_title('Distribution of User Ages')\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Number of Users')\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MKBpgol9GYdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "Ee3I8KIRB3u7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is creating a histogram to show the distribution of user ages. A histogram is a good choice for this type of data because it shows the frequency distribution of a continuous variable, such as age.\n",
        "\n",
        "In this case, the x-axis represents the age range, and the y-axis represents the frequency of users in each age range. The histogram consists of a set of bars, where each bar represents an age range and its height indicates the number of users within that range.\n",
        "\n",
        "The code also includes axis labels and a title to make the graph easy to understand. The number of bins (20) is specified to control the number of age ranges that the data is divided into, and therefore, the width of each bar.\n",
        "\n",
        "Overall, a histogram is a good choice for displaying the distribution of user ages, as it provides a clear visual representation of the age distribution in the dataset. It helps to identify the age ranges with the most users and to understand the overall age distribution of the dataset."
      ],
      "metadata": {
        "id": "VAQ6dp0_BmXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "mAXkzK-w68lZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A majority portion of users are from age group of 25 - 40."
      ],
      "metadata": {
        "id": "FEJFsYaJzOr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "yKp_l25v7cTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that a majority of users are from the age group of 25-40 can have a positive business impact as it provides valuable information to businesses that cater to this age group. For example, publishers can use this information to target their marketing campaigns towards this age group, or businesses selling books can promote books that are popular among this age group. Additionally, this information can also be useful for businesses that sell products other than books, as they can use this information to tailor their marketing efforts towards this age group."
      ],
      "metadata": {
        "id": "wRxG8FTZ5abI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of correlation between variables**"
      ],
      "metadata": {
        "id": "_OXeJLnU7Mcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Generate a heatmap to visualize the correlation matrix\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=.5)\n",
        "\n",
        "# Set the plot title\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r3aSMmRj7M5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REASON FOR CHOSING THE GRAPH**"
      ],
      "metadata": {
        "id": "dBlPsIHtBuqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen graph is a heatmap as it is used to visualize the correlation matrix between the different numerical features of the dataset. The heatmap uses a color scale to represent the correlation values, making it easy to identify highly correlated or anti-correlated features. The use of the annot=True parameter allows for the correlation values to be displayed in each cell of the heatmap, making it easier for the viewer to understand the values. Additionally, the use of the coolwarm color map enhances the visual appeal of the heatmap.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IljOBSRQBthL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSIGHTS**"
      ],
      "metadata": {
        "id": "9zKEcxSH8foS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NO as such multicollinearity found between the variables in the dataset."
      ],
      "metadata": {
        "id": "pL8hYJVT8lKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS IMPACT**"
      ],
      "metadata": {
        "id": "NjXV9IDe82-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity can cause issues with interpretation of the model and the accuracy of the predictions, so it's important to address it if it's present. Without multicollinearity, the model's coefficients can be more easily interpreted and the predictions can be more accurate."
      ],
      "metadata": {
        "id": "IEo0jh9d80nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA CONCLUSIONS**"
      ],
      "metadata": {
        "id": "7tStDuLnELbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the observations from the given dataset, we can conclude that:\n",
        "\n",
        "A large portion of books has not been rated, which might affect the accuracy of the ratings.\n",
        "\n",
        "The most popular books based on ratings are Wild Animus, The Lovely Bones, The Da Vinci Code, Divine Secrets of the Ya-Ya Sisterhood, The Red Tent, A Painted House, Snow Falling on Cedars, The Secret Life of Bees, Angels & Demons, and Where the Heart Is.\n",
        "\n",
        "The top publishers based on the number of books in the dataset are Ballantine Books, Pocket, Berkley Publishing Group, Warner Books, Harlequin, Bantam Books, Bantam Signet Book, Avon, and Penguin Books.\n",
        "\n",
        "The top three authors based on the number of books rated are Stephen King, Nora Roberts, and John Grisham.\n",
        "\n",
        "The most popular year for book publishing in the dataset is 2002.\n",
        "\n",
        "A large portion of users has not rated any book.\n",
        "\n",
        "The most frequent ratings given by users are 10 and 9.\n",
        "\n",
        "The mean age of users is around 34 years old, and the most common location of users is in the United States, with California having the highest number of users.\n",
        "\n",
        "Toronto and Chicago are the cities with the highest number of users.\n",
        "\n",
        "The majority of users are from the age group of 25-40.\n",
        "\n",
        "There is no multicollinearity found between the variables in the dataset."
      ],
      "metadata": {
        "id": "vEPvfQv5EJiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hypothesis Test 1:**\n",
        "Null Hypothesis: The proportion of books rated is greater than or equal to 50%\n",
        "\n",
        "Alternative Hypothesis: The proportion of books rated is less than 50%"
      ],
      "metadata": {
        "id": "F5a50UzqHnI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Compute proportion of books rated\n",
        "num_books_rated = len(df[df['Book-Rating'] != 0])\n",
        "total_books = len(df)\n",
        "prop_books_rated = num_books_rated / total_books\n",
        "\n",
        "# Set null hypothesis proportion\n",
        "null_prop = 0.5\n",
        "\n",
        "# Calculate z-score and p-value for one-sample proportion test\n",
        "z_score, p_value = proportions_ztest(num_books_rated, total_books, null_prop, alternative='smaller')\n",
        "\n",
        "# Set significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(f\"Proportion of books rated: {prop_books_rated:.4f}\")\n",
        "print(f\"Null Hypothesis: The proportion of books rated is greater than or equal to {null_prop:.2f}\")\n",
        "print(f\"Alternative Hypothesis: The proportion of books rated is less than {null_prop:.2f}\")\n",
        "print(f\"z-score: {z_score:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis - proportion of books rated is significantly less than 50%\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis - proportion of books rated is not significantly less than 50%\")\n"
      ],
      "metadata": {
        "id": "JH7h5XrxH4qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion of books rated: 0.3722\n",
        "\n",
        "Null Hypothesis: The proportion of books rated is greater than or equal to 0.50\n",
        "\n",
        "Alternative Hypothesis: The proportion of books rated is less than 0.50\n",
        "\n",
        "z-score: -268.3426\n",
        "\n",
        "p-value: 0.0000\n",
        "\n",
        "Reject null hypothesis - proportion of books rated is significantly less than 50%"
      ],
      "metadata": {
        "id": "XKocdg14IE_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which statistical test have you done to obtain P-Value?**"
      ],
      "metadata": {
        "id": "fJnPw_s4MCAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It uses a one-sample z-test to compare a sample proportion to a null hypothesis value."
      ],
      "metadata": {
        "id": "QvdD3iEeLgFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why did you choose the specific statistical test?**"
      ],
      "metadata": {
        "id": "kOuW5NwaMEuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific statistical test chosen in this code is a one-sample proportion test. The purpose of this test is to determine whether a proportion is significantly different from a hypothesized value. In this case, the proportion of books rated is being tested against a null hypothesis of being greater than or equal to 50%. The z-score and p-value are calculated using the proportions_ztest() function from statsmodels.stats.proportion module. The null and alternative hypotheses are defined in the print statements, and the significance level is set to alpha = 0.05. If the p-value is less than alpha, the null hypothesis is rejected and it is concluded that the proportion of books rated is significantly less than 50%. Otherwise, if the p-value is greater than alpha, the null hypothesis is not rejected, and it is concluded that there is not enough evidence to suggest that the proportion of books rated is significantly less than 50%."
      ],
      "metadata": {
        "id": "IYDIyrbzKp_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hypothesis Test 2:**\n",
        "Null Hypothesis: The average rating for the top 10 most popular books is equal to 8\n",
        "\n",
        "Alternative Hypothesis: The average rating for the top 10 most popular books is not equal to 8"
      ],
      "metadata": {
        "id": "sAXuHpVEIhPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# create a list of the top 10 most popular books based on ratings\n",
        "top_books = ['Wild Animus', 'The Lovely Bones', 'The Da Vinci Code', 'Divine Secrets of the Ya-Ya Sisterhood', \n",
        "             'The Red Tent', 'A Painted House', 'Snow Falling on Cedars', 'The Secret Life of Bees', \n",
        "             'Angels & Demons', 'Where the Heart Is']\n",
        "\n",
        "# create a subset of the dataframe with only the top 10 most popular books\n",
        "top_books_ratings = df[df['Book-Title'].isin(top_books)]\n",
        "\n",
        "# calculate the mean rating for the top 10 most popular books\n",
        "mean_rating = top_books_ratings['Book-Rating'].mean()\n",
        "\n",
        "# set the null hypothesis value\n",
        "null_hypothesis = 8\n",
        "\n",
        "# perform the one-sample t-test\n",
        "t_statistic, p_value = ttest_1samp(top_books_ratings['Book-Rating'], null_hypothesis)\n",
        "\n",
        "# print the results\n",
        "print('Mean rating for the top 10 most popular books:', mean_rating)\n",
        "print('Null hypothesis:', null_hypothesis)\n",
        "print('t-statistic:', t_statistic)\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "hydppRs-IgQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that the average rating for the top 10 most popular books is significantly different from 8."
      ],
      "metadata": {
        "id": "MurGIDlTItBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which statistical test have you done to obtain P-Value?**"
      ],
      "metadata": {
        "id": "EKKMF67LL7gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It uses a one-sample t-test to test whether the mean rating for a sample of books is significantly different from a null hypothesis value."
      ],
      "metadata": {
        "id": "2kPXk9QWLjo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why did you choose the specific statistical test?**"
      ],
      "metadata": {
        "id": "tGPYZUFeL4Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific statistical test chosen is a one-sample t-test because we are testing the mean rating of a sample (the top 10 most popular books) against a known population mean (null hypothesis of 8). This test is used when we want to determine if a sample mean is significantly different from a population mean."
      ],
      "metadata": {
        "id": "XQEj2hBUKwY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hypothesis Test 3:**\n",
        "Null Hypothesis: The mean age of users in the United States is equal to the mean age of users in other countries\n",
        "\n",
        "Alternative Hypothesis: The mean age of users in the United States is different from the mean age of users in other countries"
      ],
      "metadata": {
        "id": "ztMDuLsoI_dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Create two groups: users in the United States and users in other countries\n",
        "us_users = df[df['Country'] == 'usa']['Age'].dropna()\n",
        "other_users = df[df['Country'] != 'usa']['Age'].dropna()\n",
        "\n",
        "# Perform two-sample t-test\n",
        "t_stat, p_value = stats.ttest_ind(us_users, other_users, equal_var=False)\n",
        "\n",
        "# Print results\n",
        "print(\"Mean age of users in the United States: {:.2f}\".format(us_users.mean()))\n",
        "print(\"Mean age of users in other countries: {:.2f}\".format(other_users.mean()))\n",
        "print(\"t-statistic: {:.2f}\".format(t_stat))\n",
        "print(\"p-value: {:.10f}\".format(p_value))\n"
      ],
      "metadata": {
        "id": "9V1lZSeLI9ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean age of users in the United States is significantly higher than the mean age of users in other countries. The t-statistic of 121.38 and the p-value of 0.0 suggest that the difference in mean ages between the two groups is statistically significant, indicating that the null hypothesis of the mean age of users in the United States being equal to the mean age of users in other countries can be rejected. Therefore, we can conclude that there is a difference in mean ages between users in the United States and users in other countries."
      ],
      "metadata": {
        "id": "zZF_HfmMKQVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which statistical test have you done to obtain P-Value?**"
      ],
      "metadata": {
        "id": "p-YsdUz7LxEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It uses a two-sample t-test to test whether there is a significant difference in the mean age of users between two groups (users in the United States and users in other countries)."
      ],
      "metadata": {
        "id": "1olA_q4hLn78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why did you choose the specific statistical test?**"
      ],
      "metadata": {
        "id": "uTF__4_GL0vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample t-test was chosen because it is used to determine whether there is a significant difference between the means of two independent groups. In this case, the groups are users in the United States and users in other countries, and the objective is to determine if the mean age of users in the United States is different from the mean age of users in other countries. The two-sample t-test is appropriate because the sample sizes are greater than 30, the samples are independent, and the variances are assumed to be unequal."
      ],
      "metadata": {
        "id": "XxJT-6yzK3VW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge ratings_df and books_df on ISBN\n",
        "ratings_with_name = pd.merge(ratings_df, books_df, on='ISBN')\n",
        "\n",
        "# Filter out ratings with 0 Book-Rating\n",
        "ratings_with_name = ratings_with_name[ratings_with_name['Book-Rating']!=0]\n",
        "\n",
        "# Group by User-ID and count the number of ratings\n",
        "x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 50\n",
        "\n",
        "# Get the index of users with more than 50 ratings\n",
        "experienced_users = x[x].index\n",
        "\n",
        "# Filter ratings by experienced users\n",
        "filtered_ratings = ratings_with_name[ratings_with_name['User-ID'].isin(experienced_users)]\n",
        "\n",
        "# Group by Book-Title and count the number of ratings\n",
        "y = filtered_ratings.groupby('Book-Title').count()['Book-Rating']>=10\n",
        "\n",
        "# Get the index of books with more than 10 ratings\n",
        "famous_books = y[y].index\n",
        "\n",
        "# Filter final data by famous books\n",
        "final_data = filtered_ratings[filtered_ratings['Book-Title'].isin(famous_books)]\n",
        "\n",
        "# Remove duplicate ratings\n",
        "final_data.drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 K-NEAREST NEIGHBOUR"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def store(model,x,str1,str2):\n",
        "  metrics = {'Model_name':[model],'test_rmse':[x] ,'Hypertuned':[str1],'Cross_validate':[str2]}\n",
        "  df = pd.DataFrame(metrics)\n",
        "  return df"
      ],
      "metadata": {
        "id": "CZaXsZdcHT8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "m9Va1IGVP4o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset,Reader,KNNBasic ,accuracy"
      ],
      "metadata": {
        "id": "uAEw1YpIPrzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1,10))\n",
        "data = Dataset.load_from_df(final_data[['User-ID','ISBN','Book-Rating']],reader = reader)"
      ],
      "metadata": {
        "id": "BrzQOfJ3QVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code implements movies recommendation based on Pearson correlation and 20 nearest similar users."
      ],
      "metadata": {
        "id": "dNu-kLf8RWWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set co-efficient and similarity parameters for building model\n",
        "item_based_cosine_sim = {'name':'pearson','user_based':True}\n",
        "\n",
        "knn = KNNBasic(k=20,min_k=5,sim_options = item_based_cosine_sim)"
      ],
      "metadata": {
        "id": "L2xCoYZgQ6dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CROSS VALIDATION**"
      ],
      "metadata": {
        "id": "MMHRh8m5SMrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "cv_results = cross_validate(knn,data,measures=['RMSE'],cv = 5,verbose=False)"
      ],
      "metadata": {
        "id": "CxFgRQYOSWJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It reports test accuracy for each fold along with the time it takes to build and test the models.\n",
        "\n",
        "Let us take the average accuracy across all folds."
      ],
      "metadata": {
        "id": "QfbKA6wUSzBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from surprise import Dataset,Reader,KNNBasic ,accuracy\n",
        "reader = Reader(rating_scale=(1,10))\n",
        "data = Dataset.load_from_df(final_data[['User-ID','ISBN','Book-Rating']],reader = reader)\n",
        "#Set co-efficient and similarity parameters for building model\n",
        "item_based_cosine_sim = {'name':'pearson','user_based':True}\n",
        "\n",
        "knn = KNNBasic(k=20,min_k=5,sim_options = item_based_cosine_sim)\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "cv_results = cross_validate(knn,data,measures=['RMSE'],cv = 5,verbose=False)\n"
      ],
      "metadata": {
        "id": "A_k4fDL1e1Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.mean(cv_results.get('test_rmse'))\n"
      ],
      "metadata": {
        "id": "fhSQalNSTO0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric1 = store('KNN',x,'No','Yes')\n",
        "metric1"
      ],
      "metadata": {
        "id": "DVP3efYnIXmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model used in this code is a K-Nearest Neighbors (KNN) algorithm for Collaborative Filtering. Collaborative filtering is a technique that recommends items (books in this case) to users based on the preferences and ratings of similar users.\n",
        "\n",
        "The performance of the KNN algorithm is evaluated using the Root Mean Square Error (RMSE) metric. RMSE is a measure of the difference between predicted and actual ratings. A lower RMSE indicates better accuracy of the model in predicting ratings.\n",
        "\n",
        "In the given code, the KNN model is built using 20 nearest neighbors and a minimum of 5 neighbors required for the algorithm to work. The similarity between items is calculated using Pearson correlation coefficient.\n",
        "\n",
        "To evaluate the model's performance, 5-fold cross-validation is performed using the cross_validate() function from the Surprise library. The measures parameter is set to 'RMSE' to calculate the RMSE score. The average test RMSE across all folds is then calculated using np.mean().\n",
        "\n",
        "The test RMSE score obtained from the cross-validation is 1.75, which indicates that the model's predictions have an average error of 1.75 on a scale of 1 to 10. While this score is not very low, it can still be considered a reasonable performance for a basic KNN collaborative filtering model. However, the performance of the model may depend on various factors such as the size and quality of the dataset, the similarity measure used, and the choice of hyperparameters like the number of neighbors. It is always recommended to fine-tune the model and try different algorithms and evaluation metrics to find the best model for the given dataset."
      ],
      "metadata": {
        "id": "yus_2r4Cfc4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection.search import GridSearchCV"
      ],
      "metadata": {
        "id": "WV2CXzXmCf_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'k':[10,20],\n",
        "              'sim_options':{'name':['cosine','pearson'],'user_based':[True,False]}}\n",
        "\n",
        "grid_cv = GridSearchCV(KNNBasic,param_grid,measures=['rmse'],cv=5,refit=True)\n",
        "\n",
        "grid_cv.fit(data)"
      ],
      "metadata": {
        "id": "uHoTBK0VCvlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best RMSE score\n",
        "print(grid_cv.best_score['rmse'])\n",
        "x = grid_cv.best_score['rmse']\n",
        "#Combination of parameters that gave the best RMSE score\n",
        "print(grid_cv.best_params['rmse'])"
      ],
      "metadata": {
        "id": "Dfw5bQIZDszM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model is Item-based collaborative filtering with cosine similarity and 20 similar users.\n",
        "\n",
        "Details of the grid search are captured in the variable cv_results.We can convert it to a DataFrame and print a few columns like param_sim_options and mean_test_rmse."
      ],
      "metadata": {
        "id": "wX4g3kt_Eskd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric2 = store('KNN',x,'YES','YES')\n",
        "metric2"
      ],
      "metadata": {
        "id": "MJ7HYWoNJOW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame.from_dict(grid_cv.cv_results)\n",
        "results_df[['param_k','param_sim_options','mean_test_rmse','rank_test_rmse']].sort_values('rank_test_rmse')"
      ],
      "metadata": {
        "id": "UOk8BrEDFebs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each record represents the parameters used to build the model and the corresponding RMSE of the model.The last column rank_test_rmse shows the rank of the model as per the RMSE on test data among all the models"
      ],
      "metadata": {
        "id": "5-N2DO3NGHnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a popular hyperparameter optimization technique in machine learning. It works by exhaustively searching over a specified hyperparameter grid to find the optimal set of hyperparameters that yield the best performance on a validation set.\n",
        "\n",
        "In the code snippet, the GridSearchCV() function is used to perform a grid search over the hyperparameter grid specified in param_grid. The grid search is performed on the KNNBasic algorithm, with the measures parameter set to ['rmse'], indicating that the root mean squared error (RMSE) is used as the performance metric. The cv parameter is set to 5, indicating that 5-fold cross-validation is used to evaluate the performance of each set of hyperparameters. Finally, the refit parameter is set to True, indicating that the optimal set of hyperparameters is used to refit the model on the entire dataset.\n",
        "\n",
        "The hyperparameter grid specified in param_grid includes two hyperparameters: k and sim_options. The k hyperparameter specifies the number of neighbors to consider when making predictions, and the sim_options hyperparameter specifies the similarity metric and user-item weighting scheme to use. The grid search will search over all possible combinations of these hyperparameters and their values to find the optimal set of hyperparameters that yields the best performance on the validation set."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score1 = pd.concat([metric1,metric2]).reset_index()"
      ],
      "metadata": {
        "id": "tknycFv8KffF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score1.drop('index',axis = 1,inplace = True)\n",
        "score1"
      ],
      "metadata": {
        "id": "Ht8aue14KuzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, based on the evaluation metric score chart, there is an improvement after hyperparameter tuning.\n",
        "\n",
        "Before hyperparameter tuning, the model_name 'KNN' had a test_rmse score of 1.760964 and the model was not hypertuned. After hyperparameter tuning, the same model 'KNN' had a lower test_rmse score of 1.631374, indicating an improvement in performance. The 'Hypertuned' column shows that the model was hypertuned after the hyperparameter optimization process."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 SINGULAR VALUE DECOMPOSITION"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD\n",
        "\n",
        "#Use 5 factors for building the model\n",
        "svd = SVD(n_factors = 5)"
      ],
      "metadata": {
        "id": "k-w_TVMAMGWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us use five fold cross validation for testing models performance"
      ],
      "metadata": {
        "id": "Ogp0bq3dMXo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = cross_validate(svd,data,measures=['RMSE'],cv=5,verbose=True)"
      ],
      "metadata": {
        "id": "WLUwnJv5Lr60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.mean(cv_results.get('test_rmse'))"
      ],
      "metadata": {
        "id": "h6NkMHiyMyrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric3 = store('SVD',result,'No','YES')\n",
        "metric3"
      ],
      "metadata": {
        "id": "2vkCcTgjNCiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model used in this code is SVD (Singular Value Decomposition) for collaborative filtering in recommendation systems. SVD is a matrix factorization technique that is commonly used in recommendation systems to model the user-item interaction matrix.\n",
        "\n",
        "In the code snippet provided, the svd() function is used to create an instance of the SVD model. The data parameter is passed to the model, which contains the user-item interaction matrix. The cross_validate() function is then used to evaluate the model's performance using the RMSE (Root Mean Squared Error) as the performance metric, with 5-fold cross-validation (cv=5). The verbose parameter is set to True to display the progress of the cross-validation.\n",
        "\n",
        "The results of the cross-validation are stored in the cv_results object, which contains the average test_rmse score across the 5 folds. The test_rmse score of the SVD model is 1.511075, indicating the average error between the predicted and actual ratings for the test data. The 'Hypertuned' column shows that the model was not hypertuned, which means that the default hyperparameters were used to train the model."
      ],
      "metadata": {
        "id": "JM2veT76Njz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of evaluation metrics for a positive business impact depends on the business problem at hand. Generally, the most commonly used evaluation metrics for recommender systems are Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).\n",
        "\n",
        "In this case, the evaluation metric used is RMSE, as specified by measures=['RMSE'] in the cross_validate function. RMSE measures the square root of the average of squared differences between predicted and actual ratings. The lower the RMSE, the better the performance of the model. RMSE is often preferred over MAE because it punishes larger errors more severely, making it more sensitive to outliers."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_df = pd.concat([score1,metric3]).reset_index()\n",
        "score_df.drop('index',axis = 1,inplace = True)\n",
        "score_df"
      ],
      "metadata": {
        "id": "-CpMOv9jQLEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics, the SVD model still seems to perform the best among the three models with the lowest RMSE score of 1.51. Furthermore, the SVD model has been cross-validated, which means that its performance has been evaluated on multiple folds of the data to ensure its generalization.\n",
        "\n",
        "Even though the KNN model with hypertuning has the same RMSE score as the SVD model, it should be noted that the KNN model is a memory-based algorithm, which means that it may not scale well to larger datasets. On the other hand, the SVD model is a model-based algorithm, which can handle larger datasets efficiently.\n",
        "\n",
        "Therefore, I would still choose the SVD model as the final prediction model. However, it's important to keep in mind that the choice of the final model should not only be based on the evaluation metrics but also on the business requirements and constraints, such as model complexity, interpretability, and scalability."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "8Jp-VciNSw-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the SVD model on the entire dataset\n",
        "svd = SVD()\n",
        "trainset = data.build_full_trainset()\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Generate predictions for all user-item pairs\n",
        "testset = trainset.build_anti_testset()\n",
        "predictions = svd.test(testset)\n"
      ],
      "metadata": {
        "id": "IwANINSiSHJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predictions to a DataFrame\n",
        "pred_df = pd.DataFrame(predictions)"
      ],
      "metadata": {
        "id": "E34SMx--XH4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df"
      ],
      "metadata": {
        "id": "CbxYOiRyXKbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following function was adapted from the surprise docs\n",
        "# and can be used to get the top book recommendations for each user.\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_top_n(predictions, n=10):\n",
        "    \n",
        "    # First map the predictions to each user\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "        \n",
        "    return top_n"
      ],
      "metadata": {
        "id": "VNr9FQvCWnPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reading_list(userid):\n",
        "    \n",
        "    reading_list = defaultdict(list)\n",
        "    top_n = get_top_n(predictions, n=10)\n",
        "    for n in top_n[userid]:\n",
        "        book, rating = n\n",
        "        title = books_df.loc[books_df.ISBN==book]['Book-Title'].unique()[0]\n",
        "        reading_list[title] = rating\n",
        "    return reading_list"
      ],
      "metadata": {
        "id": "SVoRVu-fXZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a random look at user_id\n",
        "example_reading_list = get_reading_list(userid=116866)\n"
      ],
      "metadata": {
        "id": "Kt0eFTYSXf6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = []\n",
        "ratings = []\n",
        "for book, rating in example_reading_list.items():\n",
        "    books.append(book)\n",
        "    ratings.append(rating)\n",
        "\n",
        "# Create a dataframe from the two lists\n",
        "Top10_book_recommendation = pd.DataFrame({'book': books, 'rating': ratings})\n"
      ],
      "metadata": {
        "id": "Z3qCwK1Caqin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top10_book_recommendation"
      ],
      "metadata": {
        "id": "Di6dzTX2a44f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}